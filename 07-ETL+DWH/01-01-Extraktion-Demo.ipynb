{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1BL6fz2-jOCEmlbHL_LUVxhtHzK709prp","timestamp":1714904625208}],"authorship_tag":"ABX9TyPMH7zwaWjxVDEBTUoXEPHX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 01-01 Extraktion Demo"],"metadata":{"id":"SvxhKbdnO7j3"}},{"cell_type":"markdown","source":["## Konfiguration des Notebooks"],"metadata":{"id":"bbsb3U9UkAl1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1D0zfQ-IzSGk"},"outputs":[],"source":["# Ggf. fehlende Pakete installieren\n","!pip install --quiet ipython-sql petl"]},{"cell_type":"code","source":["import petl as etl\n","import csv\n","import sys\n","%load_ext sql"],"metadata":{"id":"44KM1u1Zzn3-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"KCd-QXa1OR9n"}},{"cell_type":"code","source":["# Konfiguration\n","base_url_quellen = \"https://raw.githubusercontent.com/fau-lmi/lct-ehealth/main/07-ETL+DWH/data\"\n","base_url_staging = \"./\""],"metadata":{"id":"MP1zDb_s0-rq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Hinweise zur Datenbankanbindung**\n","\n","Im folgenden Block werden die Verbindungen zur Datenbank hergestellt. Normalerweise w√ºrden wir f√ºr das Staging eine einzige Zieldatenbank nutzen, in der wir verschiedene Schemata als Namensr√§ume f√ºr die 3 Quellsysteme (Bielefeld, Mannheim, Dimensionen) nutzen w√ºrden. Die Datenbanken werden dabei als `*.sqlite`-Dateien im aktuellen Verzeichnis des Rechners angelegt, auf dem dieses Notebook ausgef√ºhrt wird."],"metadata":{"id":"yEl6JfM2mudq"}},{"cell_type":"code","source":["# Datenbankverbindung als Pfad (f√ºr das ETL) & iPython SQL (f√ºr die Abfragen) herstellen\n","db_path_stg_bielefeld  = base_url_staging + \"stg_bielefeld.sqlite\"\n","db_path_stg_mannheim   = base_url_staging + \"stg_mannheim.sqlite\"\n","db_path_stg_dimensions = base_url_staging + \"stg_dimensions.sqlite\"\n","db_path_staging        = base_url_staging + \"staging.sqlite\"\n","\n","db_url_stg_bielefeld  = \"sqlite:///\" + db_path_stg_bielefeld\n","db_url_stg_mannheim   = \"sqlite:///\" + db_path_stg_mannheim\n","db_url_stg_dimensions = \"sqlite:///\" + db_path_stg_dimensions\n","db_url_staging        = \"sqlite:///\" + db_path_staging\n","\n","%sql $db_url_stg_bielefeld\n","%sql $db_url_stg_mannheim\n","%sql $db_url_stg_dimensions\n","%sql $db_url_staging"],"metadata":{"id":"-vj4aaez2LXG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Da SQLite keine Schemata unterst√ºtzt, legen wir stattdessen 3 getrennte Staging-Datenbanken an (stg_bielefeld, stg_mannheim & stg_dimensions). SQLite erlaubt √ºber den `ATTACH DATABASE`-Befehl, diese 3 Datenbanken anschlie√üend von einer gemeinsamen Datenbank (staging) aus zu b√ºndeln und gemeinsam darauf zuzugreifen.\n","\n","Wir k√∂nnen  anschlie√üend von der √ºbergeordneten Staging-Datenbank aus gleichzeitig auf Tabellen jeder der 3 eingeh√§ngten Datenbanken zugreifen, indem wir z.B. `SELECT * FROM stg_bielefeld.faelle` schreiben (l√§dt die Daten der F√§lle-Tabelle der Bielefelder Staging-Datenbank)."],"metadata":{"id":"v3zUK0IEnDb_"}},{"cell_type":"code","source":["%%sql $db_url_staging\n","ATTACH DATABASE :db_path_stg_bielefeld  AS bielefeld;\n","ATTACH DATABASE :db_path_stg_mannheim   AS mannheim;\n","ATTACH DATABASE :db_path_stg_dimensions AS dimensions;"],"metadata":{"id":"Qpl48MBD2LfC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Rohdatentabelle extrahieren und in Staging-Bereich laden\n","\n","In den folgenden Blocks nutzen wir das PETL-Paket, um mit wenigen Befehlen die Tabelle 'standorte.tsv' aus den Dimensions-Rohdaten in die Staging-Datenbank stg_dimensions zu √ºbertragen.\n","\n","### 1. Zieltabelle anlegen\n","\n","Hierzu legen wir zun√§chst mit einem CREATE-Table die Tabelle in der Staging-Datenbank (leer) an.\n","\n","üí° *Hinweis:* Der Code zur Anlage der Tabelle muss in einer eigenen Zelle stehen, da der `%%sql`-Befehl f√ºr mehrzeilige SQL-Statements nicht gemeinsam mit anderen Befehlen im gleichen Block verarbeitet werden kann."],"metadata":{"id":"mfEtqN2sne-F"}},{"cell_type":"code","source":["%%sql $db_url_staging\n","DROP TABLE IF EXISTS dimensions.standorte;\n","CREATE TABLE dimensions.standorte (\n","  standort_id   VARCHAR(1),\n","  standort_name VARCHAR(20)\n",");"],"metadata":{"id":"-bb8aZtj-nFA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Daten aus Quelldatei auslesen & in Zieltabelle schreiben\n","\n","Als n√§chstes laden wir mit der PETL-Funktion `fromtsv()` die Quelldaten aus der Datei 'standorte.tsv' und speichern diese direkt anschlie√üend mit der PETL-Funktion `todb()` in die Zieldatenbank stg_dimensions.\n","\n","Bei der Funktion `fromtsv()` muss im Regelfall nur der Pfad/Dateiname der zu ladenden Datei angegeben werden. Alternativ kann mit `fromcsv()` auch eine Komma-getrennte Datei geladen bzw. mit dem Parameter `delimiter=\";\"` ein anderes Trennzeichen vorgegeben werden.\n","\n","Bei der Funktion `todb()` m√ºssen die geladene Datentabelle, die Datenbankverbindung und der Name der Tabelle in der Zieldatenbank angegeben werden. Optional kann mit dem Parameter `create=True` angegeben werden, dass die Tabelle automatisch in der Zieldatenbank angelegt werden soll. Hierbei werden allerdings (bei zuvor aus TSV/CSV-Dateien geladenen Rohdaten) nicht immer die korrekten Datentypen verwendet. Es ist deshalb sinnvoll, die Tabelle vorher manuell per `CREATE TABLE`-Statement anzulegen. Die Zieltabelle wird von der Funktion zun√§chst geleert und dann mit den Inhalten neu beladen. Wenn die vorhandenen Inhalte bestehen bleiben sollen, muss statt `todb()` die PETL-Funktion `appenddb()` genutzt werden.\n","\n","Dokumentation zu PETL ist hier verf√ºgbar: https://petl.readthedocs.io/en/stable/io.html"],"metadata":{"id":"Wrjb1_5xoNF8"}},{"cell_type":"code","source":["table_data = etl.fromtsv(base_url_quellen + \"/dimensionen/standorte.tsv\")\n","etl.todb(table_data, db_path_stg_dimensions, 'standorte')"],"metadata":{"id":"fJQq8K0--nHe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. Ergebniskontrolle\n","\n","Anschlie√üend k√∂nnen wir mit einer `SELECT`-Abfrage √ºberpr√ºfen, ob die Tabelle korrekt √ºbertragen wurde.\n","\n","üí° *Tipp:* Wenn Sie mit einer `SELECT * FROM tabelle`-Abfrage pr√ºfen wollen, ob Inhalte vorhanden sind, k√∂nnen ggf. sehr gro√üe Datenmengen in das Colab-Notebook geladen werden, was die Laufzeitumgebung bzw. den Browser zum Absturz bringen kann. Erg√§nzen Sie deshalb immer eine `LIMIT <Zahl>`-Klausel am Ende der Abfrage, so dass nur eine feste Zahl von Datens√§tzen geladen wird."],"metadata":{"id":"kf4Zkcu2qU55"}},{"cell_type":"code","source":["%%sql $db_url_staging\n","SELECT *\n","  FROM dimensions.standorte\n"," LIMIT 10"],"metadata":{"id":"d3REna2T-nNb"},"execution_count":null,"outputs":[]}]}